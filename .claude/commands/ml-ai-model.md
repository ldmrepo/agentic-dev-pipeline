# ML/AI ëª¨ë¸ ê°œë°œ ì›Œí¬í”Œë¡œìš°

## ğŸ¤– End-to-End ML/AI ëª¨ë¸ ê°œë°œ ìë™í™”
**ëª©í‘œ ì™„ë£Œ ì‹œê°„: 3-4ì‹œê°„**

ë‹¤ìŒì˜ ML/AI ëª¨ë¸ì„ ê°œë°œí•´ì£¼ì„¸ìš”: $ARGUMENTS

## ì›Œí¬í”Œë¡œìš° ë‹¨ê³„

### 1ë‹¨ê³„: ë¬¸ì œ ì •ì˜ ë° ë°ì´í„° ë¶„ì„ (30ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### ë¬¸ì œ ì •ì˜
- ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ëª…í™•í™”
- ML ë¬¸ì œ ìœ í˜• ê²°ì • (ë¶„ë¥˜/íšŒê·€/í´ëŸ¬ìŠ¤í„°ë§/ì¶”ì²œ)
- ì„±ê³µ ë©”íŠ¸ë¦­ ì •ì˜ (ì •í™•ë„, F1, AUC, RMSE ë“±)
- ì œì•½ì‚¬í•­ íŒŒì•… (ë ˆì´í„´ì‹œ, ëª¨ë¸ í¬ê¸°, ì„¤ëª…ê°€ëŠ¥ì„±)

#### ë°ì´í„° íƒìƒ‰ (EDA)
```python
# notebooks/eda.ipynb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from ydata_profiling import ProfileReport

# ë°ì´í„° í”„ë¡œíŒŒì¼ë§
profile = ProfileReport(df, title="ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸")
profile.to_file("reports/data_profile.html")

# ì‹œê°í™” ë° í†µê³„ ë¶„ì„
# ê²°ì¸¡ì¹˜ ë¶„ì„
# ì´ìƒì¹˜ íƒì§€
# íŠ¹ì„± ë¶„í¬ ë¶„ì„
# ìƒê´€ê´€ê³„ ë¶„ì„
```

#### ë°ì´í„° í’ˆì§ˆ í‰ê°€
- ë°ì´í„° ì™„ì „ì„± ê²€ì‚¬
- ë ˆì´ë¸” ë¶ˆê· í˜• ë¶„ì„
- ë°ì´í„° ëˆ„ìˆ˜ ê²€ì‚¬
- ì‹œê°„ì  ì¼ê´€ì„± ê²€ì¦

docs/ml-project/ ë””ë ‰í† ë¦¬ì— ìƒì„±:
- problem_definition.md
- data_analysis_report.md
- ml_requirements.md

### 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ ë° íŠ¹ì„± ê³µí•™ (45ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### ë°ì´í„° ì „ì²˜ë¦¬
```python
# src/preprocessing/data_preprocessor.py
class DataPreprocessor:
    def __init__(self):
        self.scalers = {}
        self.encoders = {}
        self.imputers = {}
    
    def clean_data(self, df):
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        # ì´ìƒì¹˜ ì œê±°/ë³€í™˜
        # ë°ì´í„° íƒ€ì… ë³€í™˜
        pass
    
    def handle_missing_values(self, df):
        # ìˆ˜ì¹˜í˜•: í‰ê· /ì¤‘ì•™ê°’/ë³´ê°„
        # ë²”ì£¼í˜•: ìµœë¹ˆê°’/ìƒˆ ì¹´í…Œê³ ë¦¬
        pass
    
    def remove_outliers(self, df):
        # IQR ë°©ë²•
        # Z-score ë°©ë²•
        # Isolation Forest
        pass
```

#### íŠ¹ì„± ê³µí•™
```python
# src/features/feature_engineering.py
class FeatureEngineer:
    def create_features(self, df):
        # ìƒí˜¸ì‘ìš© íŠ¹ì„±
        # ë‹¤í•­ì‹ íŠ¹ì„±
        # ë„ë©”ì¸ íŠ¹í™” íŠ¹ì„±
        # ì‹œê³„ì—´ íŠ¹ì„± (lag, rolling)
        pass
    
    def encode_categorical(self, df):
        # One-hot encoding
        # Target encoding
        # Ordinal encoding
        # Embedding
        pass
    
    def scale_features(self, df):
        # StandardScaler
        # MinMaxScaler
        # RobustScaler
        # Normalizer
        pass
```

#### íŠ¹ì„± ì„ íƒ
```python
# src/features/feature_selection.py
from sklearn.feature_selection import (
    SelectKBest, RFE, SelectFromModel
)

class FeatureSelector:
    def select_features(self, X, y):
        # í†µê³„ì  ë°©ë²• (chi2, ANOVA)
        # ëª¨ë¸ ê¸°ë°˜ (Lasso, Random Forest)
        # ìˆœì°¨ì  ì„ íƒ
        # ì¤‘ìš”ë„ ê¸°ë°˜
        pass
```

### 3ë‹¨ê³„: ëª¨ë¸ ê°œë°œ ë° ì‹¤í—˜ (60ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### AutoML êµ¬í˜„
```python
# src/models/automl.py
import optuna
from sklearn.model_selection import cross_val_score

class AutoMLPipeline:
    def __init__(self):
        self.best_model = None
        self.best_params = None
        self.study = None
    
    def objective(self, trial):
        # ëª¨ë¸ ì„ íƒ
        model_name = trial.suggest_categorical(
            'model', ['rf', 'xgb', 'lgb', 'nn']
        )
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
        if model_name == 'rf':
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'max_depth': trial.suggest_int('max_depth', 3, 20),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20)
            }
        # ... ë‹¤ë¥¸ ëª¨ë¸ë“¤
        
        # êµì°¨ ê²€ì¦
        score = cross_val_score(model, X, y, cv=5).mean()
        return score
    
    def run_automl(self, X, y, n_trials=100):
        self.study = optuna.create_study(direction='maximize')
        self.study.optimize(
            lambda trial: self.objective(trial), 
            n_trials=n_trials
        )
```

#### ë”¥ëŸ¬ë‹ ëª¨ë¸ (PyTorch/TensorFlow)
```python
# src/models/deep_learning.py
import torch
import torch.nn as nn

class NeuralNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dims, output_dim):
        super().__init__()
        layers = []
        
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        self.model = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.model(x)

# íŠ¸ë ˆì´ë‹ ë£¨í”„
class Trainer:
    def train(self, model, train_loader, val_loader, epochs=100):
        optimizer = torch.optim.Adam(model.parameters())
        criterion = nn.CrossEntropyLoss()
        
        for epoch in range(epochs):
            # íŠ¸ë ˆì´ë‹
            # ê²€ì¦
            # Early stopping
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            pass
```

#### ì•™ìƒë¸” ë°©ë²•
```python
# src/models/ensemble.py
class EnsembleModel:
    def __init__(self):
        self.models = []
        self.weights = []
    
    def add_model(self, model, weight=1.0):
        self.models.append(model)
        self.weights.append(weight)
    
    def predict(self, X):
        # Voting
        # Averaging
        # Stacking
        # Blending
        pass
```

### 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ë° ê²€ì¦ (30ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### í‰ê°€ ë©”íŠ¸ë¦­
```python
# src/evaluation/metrics.py
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    roc_auc_score, confusion_matrix, mean_squared_error
)

class ModelEvaluator:
    def evaluate_classification(self, y_true, y_pred):
        metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, average='weighted'),
            'recall': recall_score(y_true, y_pred, average='weighted'),
            'f1': f1_score(y_true, y_pred, average='weighted'),
            'auc_roc': roc_auc_score(y_true, y_pred_proba)
        }
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_true, y_pred)
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
        per_class = precision_recall_fscore_support(y_true, y_pred)
        
        return metrics, cm, per_class
    
    def evaluate_regression(self, y_true, y_pred):
        metrics = {
            'mse': mean_squared_error(y_true, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred)
        }
        return metrics
```

#### êµì°¨ ê²€ì¦
```python
# src/evaluation/cross_validation.py
from sklearn.model_selection import (
    KFold, StratifiedKFold, TimeSeriesSplit
)

class CrossValidator:
    def validate(self, model, X, y, cv_strategy='stratified'):
        if cv_strategy == 'stratified':
            cv = StratifiedKFold(n_splits=5, shuffle=True)
        elif cv_strategy == 'time_series':
            cv = TimeSeriesSplit(n_splits=5)
        else:
            cv = KFold(n_splits=5, shuffle=True)
        
        scores = []
        for train_idx, val_idx in cv.split(X, y):
            # í›ˆë ¨ ë° í‰ê°€
            pass
        
        return scores
```

#### ëª¨ë¸ í•´ì„
```python
# src/interpretation/explainability.py
import shap
import lime

class ModelInterpreter:
    def explain_with_shap(self, model, X):
        explainer = shap.Explainer(model)
        shap_values = explainer(X)
        
        # SHAP ì‹œê°í™”
        shap.summary_plot(shap_values, X)
        shap.waterfall_plot(shap_values[0])
        
        return shap_values
    
    def explain_with_lime(self, model, X, instance):
        explainer = lime.tabular.LimeTabularExplainer(
            X.values,
            feature_names=X.columns,
            mode='classification'
        )
        
        explanation = explainer.explain_instance(
            instance, 
            model.predict_proba
        )
        
        return explanation
```

### 5ë‹¨ê³„: MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (45ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### MLflow ì‹¤í—˜ ì¶”ì 
```python
# src/mlops/experiment_tracking.py
import mlflow
import mlflow.sklearn

class ExperimentTracker:
    def __init__(self, experiment_name):
        mlflow.set_experiment(experiment_name)
    
    def log_experiment(self, model, params, metrics, artifacts):
        with mlflow.start_run():
            # íŒŒë¼ë¯¸í„° ë¡œê¹…
            mlflow.log_params(params)
            
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            mlflow.log_metrics(metrics)
            
            # ëª¨ë¸ ë¡œê¹…
            mlflow.sklearn.log_model(model, "model")
            
            # ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
            for artifact in artifacts:
                mlflow.log_artifact(artifact)
            
            # íƒœê·¸ ì¶”ê°€
            mlflow.set_tags({
                "model_type": type(model).__name__,
                "version": "1.0"
            })
```

#### DVC ë°ì´í„° ë²„ì „ ê´€ë¦¬
```yaml
# dvc.yaml
stages:
  prepare:
    cmd: python src/prepare_data.py
    deps:
      - src/prepare_data.py
      - data/raw
    outs:
      - data/processed
    params:
      - prepare.split_ratio
      - prepare.seed
  
  train:
    cmd: python src/train_model.py
    deps:
      - src/train_model.py
      - data/processed
    outs:
      - models/model.pkl
    metrics:
      - metrics/scores.json
    params:
      - train.n_estimators
      - train.max_depth
```

#### ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
```python
# src/mlops/model_registry.py
class ModelRegistry:
    def __init__(self):
        self.client = mlflow.tracking.MlflowClient()
    
    def register_model(self, run_id, model_name):
        # ëª¨ë¸ ë“±ë¡
        model_uri = f"runs:/{run_id}/model"
        model_version = mlflow.register_model(
            model_uri, 
            model_name
        )
        
        # ìŠ¤í…Œì´ì§€ ì „í™˜
        self.client.transition_model_version_stage(
            name=model_name,
            version=model_version.version,
            stage="Staging"
        )
        
        return model_version
    
    def promote_to_production(self, model_name, version):
        self.client.transition_model_version_stage(
            name=model_name,
            version=version,
            stage="Production"
        )
```

### 6ë‹¨ê³„: ëª¨ë¸ ë°°í¬ (30ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### REST API ì„œë²„
```python
# src/serving/api_server.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib

app = FastAPI()

# ëª¨ë¸ ë¡œë“œ
model = joblib.load("models/production_model.pkl")

class PredictionRequest(BaseModel):
    features: list

class PredictionResponse(BaseModel):
    prediction: float
    confidence: float

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    try:
        prediction = model.predict([request.features])[0]
        confidence = model.predict_proba([request.features]).max()
        
        return PredictionResponse(
            prediction=prediction,
            confidence=confidence
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

#### Docker ì»¨í…Œì´ë„ˆí™”
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ ./src/
COPY models/ ./models/

EXPOSE 8000

CMD ["uvicorn", "src.serving.api_server:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Kubernetes ë°°í¬
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-model
  template:
    metadata:
      labels:
        app: ml-model
    spec:
      containers:
      - name: ml-model
        image: ml-model:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

### 7ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜ (30ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### ëª¨ë¸ ëª¨ë‹ˆí„°ë§
```python
# src/monitoring/model_monitor.py
from evidently import Dashboard
from evidently.tabs import DataDriftTab, CatTargetDriftTab

class ModelMonitor:
    def __init__(self):
        self.dashboard = Dashboard(tabs=[
            DataDriftTab(),
            CatTargetDriftTab()
        ])
    
    def detect_drift(self, reference_data, current_data):
        self.dashboard.calculate(
            reference_data, 
            current_data
        )
        
        # ë“œë¦¬í”„íŠ¸ ê°ì§€
        drift_report = self.dashboard.json()
        
        # ì•Œë¦¼ ë°œì†¡
        if drift_report['data_drift']['dataset_drift']:
            self.send_alert("Data drift detected!")
        
        return drift_report
    
    def monitor_performance(self, predictions, actuals):
        # ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 
        # ì •í™•ë„ í•˜ë½ ê°ì§€
        # ì˜ˆì¸¡ ë¶„í¬ ëª¨ë‹ˆí„°ë§
        pass
```

#### A/B í…ŒìŠ¤íŒ…
```python
# src/deployment/ab_testing.py
class ABTestManager:
    def __init__(self):
        self.model_a = None
        self.model_b = None
        self.traffic_split = 0.5
    
    def route_request(self, request):
        if random.random() < self.traffic_split:
            return self.model_a.predict(request)
        else:
            return self.model_b.predict(request)
    
    def analyze_results(self):
        # ì„±ëŠ¥ ë¹„êµ
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì •
        # ìŠ¹ì ê²°ì •
        pass
```

#### ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸
```python
# src/retraining/auto_retrain.py
class AutoRetrainer:
    def __init__(self):
        self.performance_threshold = 0.8
        self.drift_threshold = 0.1
    
    def should_retrain(self, current_performance, drift_score):
        return (
            current_performance < self.performance_threshold or
            drift_score > self.drift_threshold
        )
    
    def retrain_pipeline(self):
        # ìƒˆ ë°ì´í„° ìˆ˜ì§‘
        # ë°ì´í„° ì „ì²˜ë¦¬
        # ëª¨ë¸ í•™ìŠµ
        # ê²€ì¦
        # ë°°í¬
        pass
```

### 8ë‹¨ê³„: ë¬¸ì„œí™” ë° ì¸ìˆ˜ì¸ê³„ (20ë¶„)

ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

#### ëª¨ë¸ ë¬¸ì„œ
- ëª¨ë¸ ì¹´ë“œ ìƒì„±
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- í•œê³„ì  ë° í¸í–¥ì„±
- ì‚¬ìš© ê°€ì´ë“œ

#### API ë¬¸ì„œ
- OpenAPI ìŠ¤í™
- ì˜ˆì œ ìš”ì²­/ì‘ë‹µ
- ì—ëŸ¬ ì²˜ë¦¬
- ì¸ì¦ ë°©ë²•

#### ìš´ì˜ ê°€ì´ë“œ
- ë°°í¬ ì ˆì°¨
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- ë¡¤ë°± ì ˆì°¨

ìµœì¢… ì‚°ì¶œë¬¼:
- í”„ë¡œë•ì…˜ ì¤€ë¹„ëœ ML ëª¨ë¸
- ì™„ì „í•œ MLOps íŒŒì´í”„ë¼ì¸
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- API ì„œë²„ ë° ë¬¸ì„œ
- ì¬í•™ìŠµ ìë™í™”

ê° ë‹¨ê³„ë³„ë¡œ ì§„í–‰ ìƒí™©ì„ ë³´ê³ í•˜ê³ , ëª¨ë“  ì½”ë“œì™€ ì„¤ì •ì„ ìƒì„±í•´ì¤˜.