# ê¸°ìˆ  ì‹¬í™” ë¶„ì„: Claude Code & LangGraph

## ğŸ“š ëª©ì°¨
1. [Claude Code ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­](#claude-code-ê¸°ìˆ -ì„¸ë¶€ì‚¬í•­)
2. [LangGraph ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­](#langgraph-ê¸°ìˆ -ì„¸ë¶€ì‚¬í•­)
3. [í†µí•© ì•„í‚¤í…ì²˜ ì‹¬í™”](#í†µí•©-ì•„í‚¤í…ì²˜-ì‹¬í™”)
4. [êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­](#êµ¬í˜„-ì‹œ-ì£¼ì˜ì‚¬í•­)

## Claude Code ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### 1. í•µì‹¬ ì•„í‚¤í…ì²˜

#### ì„¤ì¹˜ ë° ìš”êµ¬ì‚¬í•­
```bash
# Node.js 18+ í•„ìˆ˜
npm install -g @anthropic-ai/claude-code

# í”„ë¡œì íŠ¸ì—ì„œ ì‹¤í–‰
cd your-project
claude
```

#### ì£¼ìš” íŠ¹ì§•
- **í„°ë¯¸ë„ ê¸°ë°˜**: GUI ì—†ì´ CLI í™˜ê²½ì—ì„œ ì§ì ‘ ì‘ë™
- **íŒŒì¼ í¸ì§‘ ê¶Œí•œ**: í”„ë¡œì íŠ¸ íŒŒì¼ ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥
- **ëª…ë ¹ ì‹¤í–‰**: ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì‹¤í–‰ ê¶Œí•œ
- **Git í†µí•©**: ì»¤ë°‹ ìƒì„± ë° ë²„ì „ ê´€ë¦¬
- **Unix ì² í•™**: íŒŒì´í”„ë¼ì¸ ê°€ëŠ¥, ìŠ¤í¬ë¦½íŠ¸í™” ê°€ëŠ¥

### 2. MCP (Model Context Protocol) í†µí•©

#### MCP ì„œë²„ íƒ€ì…
```javascript
// MCP ì„œë²„ ì„¤ì • ì˜ˆì‹œ
{
  "mcpServers": {
    // íŒŒì¼ì‹œìŠ¤í…œ ì ‘ê·¼
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem"],
      "env": {}
    },
    // GitHub í†µí•©
    "github": {
      "command": "npx", 
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${GITHUB_TOKEN}"
      }
    },
    // ì»¤ìŠ¤í…€ ì„œë²„
    "custom-tools": {
      "command": "python",
      "args": ["mcp_server.py"],
      "env": {
        "API_KEY": "${CUSTOM_API_KEY}"
      }
    }
  }
}
```

#### MCP í†µì‹  í”„ë¡œí† ì½œ
- **stdio**: í‘œì¤€ ì…ì¶œë ¥ (ê¸°ë³¸)
- **WebSockets**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **HTTP SSE**: ì„œë²„ ì „ì†¡ ì´ë²¤íŠ¸ (ë ˆê±°ì‹œ)
- **Streamable HTTP**: ì„œë²„ë¦¬ìŠ¤ ìµœì í™” (2025 ì‹ ê·œ)

### 3. ë°°í¬ ì˜µì…˜

```python
# ë‹¤ì–‘í•œ ë°°í¬ í™˜ê²½ ì§€ì›
deployment_options = {
    "anthropic_api": {
        "endpoint": "https://api.anthropic.com",
        "auth": "API_KEY"
    },
    "amazon_bedrock": {
        "region": "us-east-1",
        "model_id": "anthropic.claude-v3"
    },
    "google_vertex": {
        "project_id": "your-project",
        "location": "us-central1"
    },
    "corporate_proxy": {
        "proxy_url": "http://corp-proxy:8080",
        "auth_method": "NTLM"
    }
}
```

## LangGraph ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### 1. ê·¸ë˜í”„ êµ¬ì„± ìš”ì†Œ

#### State ì •ì˜
```python
from typing import TypedDict, Annotated, List
from langgraph.graph.message import add_messages
import operator

# ë‹¤ì–‘í•œ State ì •ì˜ ë°©ë²•
# 1. TypedDict ì‚¬ìš©
class WorkflowState(TypedDict):
    messages: Annotated[List[Message], add_messages]  # ë‚´ì¥ ë¦¬ë“€ì„œ
    current_task: str
    results: Annotated[dict, operator.or_]  # ì»¤ìŠ¤í…€ ë¦¬ë“€ì„œ
    
# 2. Pydantic ëª¨ë¸ ì‚¬ìš©
from pydantic import BaseModel

class PydanticState(BaseModel):
    messages: List[Message]
    metadata: dict
    
# 3. Dataclass ì‚¬ìš©
from dataclasses import dataclass

@dataclass
class DataclassState:
    messages: List[Message]
    context: dict
```

#### Node êµ¬í˜„
```python
# ë™ê¸° ë…¸ë“œ
def planning_node(state: WorkflowState, config: RunnableConfig) -> dict:
    """ë™ê¸° ë…¸ë“œ í•¨ìˆ˜"""
    # ìƒíƒœ ì½ê¸°
    current_task = state["current_task"]
    
    # ì²˜ë¦¬ ë¡œì§
    result = process_task(current_task)
    
    # ë¶€ë¶„ ìƒíƒœ ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "results": result,
        "messages": [AIMessage(content=f"Completed: {current_task}")]
    }

# ë¹„ë™ê¸° ë…¸ë“œ
async def async_development_node(
    state: WorkflowState, 
    config: RunnableConfig,
    runtime: Runtime
) -> dict:
    """ë¹„ë™ê¸° ë…¸ë“œ í•¨ìˆ˜"""
    # Runtime ê°ì²´ í™œìš©
    store = runtime.store
    stream_writer = runtime.stream_writer
    
    # ë¹„ë™ê¸° ì²˜ë¦¬
    result = await generate_code_async(state["requirements"])
    
    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    await stream_writer.write({"progress": "Code generation complete"})
    
    return {"generated_code": result}
```

#### Edge ì •ì˜
```python
from langgraph.graph import StateGraph, END

# ì¡°ê±´ë¶€ ì—£ì§€
def route_by_task_type(state: WorkflowState) -> str:
    """íƒœìŠ¤í¬ íƒ€ì…ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
    task_type = state.get("task_type")
    
    if task_type == "hotfix":
        return "fast_track"
    elif task_type == "feature":
        return "full_pipeline"
    else:
        return "planning"

# ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(WorkflowState)

# ë…¸ë“œ ì¶”ê°€
graph.add_node("analyze", analyze_node)
graph.add_node("planning", planning_node)
graph.add_node("development", async_development_node)

# ì—£ì§€ ì¶”ê°€
graph.add_edge("analyze", "planning")  # ê³ ì • ì—£ì§€
graph.add_conditional_edges(
    "planning",
    route_by_task_type,
    {
        "fast_track": "hotfix_node",
        "full_pipeline": "development",
        "planning": "detailed_planning"
    }
)
```

### 2. ì‹¤í–‰ ëª¨ë¸

#### ë©”ì‹œì§€ íŒ¨ì‹± ì•„í‚¤í…ì²˜
```python
# Pregel ê¸°ë°˜ Super-step ì‹¤í–‰
"""
Super-step 1: [analyze_node]
Super-step 2: [planning_node]
Super-step 3: [development_node, testing_node]  # ë³‘ë ¬ ì‹¤í–‰
Super-step 4: [deployment_node]
"""

# ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ Send API
from langgraph.graph import Send

def orchestrator_node(state: WorkflowState) -> list[Send]:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë…¸ë“œ - ë™ì  ì›Œì»¤ ìƒì„±"""
    tasks = state["tasks"]
    
    # ê° íƒœìŠ¤í¬ì— ëŒ€í•´ ì›Œì»¤ ë…¸ë“œ ìƒì„±
    return [
        Send("worker", {"task": task, "id": i}) 
        for i, task in enumerate(tasks)
    ]
```

#### ë¹„ë™ê¸° ì‹¤í–‰
```python
# ë¹„ë™ê¸° ê·¸ë˜í”„ ì‹¤í–‰
from langgraph.graph import CompiledGraph

compiled_graph: CompiledGraph = graph.compile()

# ë‹¨ì¼ ì…ë ¥ ë¹„ë™ê¸° ì‹¤í–‰
result = await compiled_graph.ainvoke({
    "messages": [HumanMessage(content="Build a TODO app")],
    "task_type": "feature"
})

# ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
async for chunk in compiled_graph.astream({
    "messages": [HumanMessage(content="Build a TODO app")]
}):
    print(f"Progress: {chunk}")

# ë°°ì¹˜ ì‹¤í–‰
results = await compiled_graph.abatch([
    {"task": "task1"},
    {"task": "task2"},
    {"task": "task3"}
])
```

### 3. ìƒíƒœ ê´€ë¦¬ ë° ì§€ì†ì„±

#### Checkpointer ì‚¬ìš©
```python
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.checkpoint.memory import MemorySaver

# PostgreSQL ì²´í¬í¬ì¸í„°
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost:5432/langgraph"
)

# ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„° (ê°œë°œìš©)
memory_checkpointer = MemorySaver()

# ì²´í¬í¬ì¸í„°ì™€ í•¨ê»˜ ì»´íŒŒì¼
graph = graph.compile(checkpointer=checkpointer)

# ìƒíƒœ ì €ì¥ê³¼ í•¨ê»˜ ì‹¤í–‰
config = {"configurable": {"thread_id": "user-123"}}
result = await graph.ainvoke(input_data, config=config)

# ìƒíƒœ ë³µì›
state = await graph.aget_state(config)
print(f"Current state: {state.values}")

# ìƒíƒœ íˆìŠ¤í† ë¦¬
async for state in graph.aget_state_history(config):
    print(f"Historical state: {state}")
```

#### ìƒíƒœ ë§ˆì´ê·¸ë ˆì´ì…˜
```python
# ê·¸ë˜í”„ ì •ì˜ ë³€ê²½ ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜
# 1. ì™„ë£Œëœ ìŠ¤ë ˆë“œ: ì „ì²´ í† í´ë¡œì§€ ë³€ê²½ ê°€ëŠ¥
# 2. ì¤‘ë‹¨ëœ ìŠ¤ë ˆë“œ: ë…¸ë“œ ì´ë¦„ ë³€ê²½/ì œê±° ì œì™¸í•˜ê³  ëª¨ë‘ ê°€ëŠ¥

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì‹œ
def migrate_state(old_state: dict) -> dict:
    """ì´ì „ ìƒíƒœë¥¼ ìƒˆ í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    new_state = {
        "messages": old_state.get("messages", []),
        "new_field": "default_value",  # ìƒˆ í•„ë“œ ì¶”ê°€
        # old_field ì œê±°
    }
    return new_state
```

## í†µí•© ì•„í‚¤í…ì²˜ ì‹¬í™”

### 1. Claude Code + LangGraph í†µí•© íŒ¨í„´

```python
# MCP ì„œë²„ë¡œ LangGraph ë…¸ì¶œ
class LangGraphMCPServer:
    def __init__(self, graph: CompiledGraph):
        self.graph = graph
        
    async def handle_request(self, request: dict) -> dict:
        """MCP ìš”ì²­ ì²˜ë¦¬"""
        command = request["command"]
        
        if command == "execute_workflow":
            result = await self.graph.ainvoke(request["params"])
            return {"status": "success", "result": result}
            
        elif command == "get_state":
            state = await self.graph.aget_state(request["config"])
            return {"state": state.values}
```

### 2. ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬

```python
from langgraph.errors import GraphRecursionError
from tenacity import retry, stop_after_attempt, wait_exponential

class ResilientAgent:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10)
    )
    async def execute_with_retry(self, state: dict):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì‹¤í–‰"""
        try:
            result = await self.graph.ainvoke(state)
            return result
        except GraphRecursionError:
            # ë¬´í•œ ë£¨í”„ ê°ì§€
            return {"error": "Recursion limit reached"}
        except Exception as e:
            # ìƒíƒœ ì²´í¬í¬ì¸íŠ¸ë¡œ ë¡¤ë°±
            await self.rollback_to_checkpoint()
            raise
```

### 3. ì„±ëŠ¥ ìµœì í™”

```python
# ë…¸ë“œ ìºì‹± ì„¤ì •
from langgraph.cache import NodeCache

cache = NodeCache(
    ttl=3600,  # 1ì‹œê°„ ìºì‹œ
    max_size=1000  # ìµœëŒ€ 1000ê°œ í•­ëª©
)

# ë…¸ë“œì— ìºì‹± ì ìš©
@cache.cached(key_func=lambda state: state["task_id"])
async def expensive_analysis_node(state: WorkflowState):
    """ë¹„ìš©ì´ ë†’ì€ ë¶„ì„ ì‘ì—…"""
    # ìºì‹œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
    result = await perform_expensive_analysis(state)
    return {"analysis_result": result}

# ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
from concurrent.futures import ThreadPoolExecutor
import asyncio

async def parallel_processing_node(state: WorkflowState):
    """CPU ì§‘ì•½ì  ì‘ì—…ì˜ ë³‘ë ¬ ì²˜ë¦¬"""
    executor = ThreadPoolExecutor(max_workers=4)
    
    tasks = state["tasks"]
    loop = asyncio.get_event_loop()
    
    # CPU ë°”ìš´ë“œ ì‘ì—…ì„ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
    futures = [
        loop.run_in_executor(executor, process_task, task)
        for task in tasks
    ]
    
    results = await asyncio.gather(*futures)
    return {"processed_results": results}
```

## êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­

### 1. Claude Code ê´€ë ¨

#### API í•œê³„
- **í† í° ì œí•œ**: ìš”ì²­ë‹¹ ìµœëŒ€ 200K í† í°
- **ì‹¤í–‰ ì‹œê°„**: ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ ì œí•œ ì¡´ì¬
- **íŒŒì¼ í¬ê¸°**: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ ì²­í¬ ë¶„í•  í•„ìš”

#### ë³´ì•ˆ ê³ ë ¤ì‚¬í•­
```python
# MCP ì„œë²„ ë³´ì•ˆ ì„¤ì •
security_config = {
    "allowed_commands": ["read", "write", "execute"],
    "forbidden_paths": ["/etc", "/sys", "/proc"],
    "max_file_size": 10 * 1024 * 1024,  # 10MB
    "timeout": 300  # 5ë¶„
}
```

### 2. LangGraph ê´€ë ¨

#### ìƒíƒœ í¬ê¸° ê´€ë¦¬
```python
# í° ìƒíƒœ ì²˜ë¦¬ ì‹œ ì™¸ë¶€ ì €ì¥ì†Œ í™œìš©
class LargeStateHandler:
    def __init__(self, s3_client):
        self.s3 = s3_client
        
    async def save_large_data(self, state: dict, key: str):
        """í° ë°ì´í„°ëŠ” S3ì— ì €ì¥í•˜ê³  ì°¸ì¡°ë§Œ ìœ ì§€"""
        if len(str(state[key])) > 1024 * 1024:  # 1MB ì´ìƒ
            s3_key = f"large_data/{state['thread_id']}/{key}"
            await self.s3.put_object(
                Bucket="langgraph-data",
                Key=s3_key,
                Body=json.dumps(state[key])
            )
            state[key] = {"__ref": s3_key}
        return state
```

#### ë¬´í•œ ë£¨í”„ ë°©ì§€
```python
# ì¬ê·€ ì œí•œ ì„¤ì •
graph = graph.compile(
    checkpointer=checkpointer,
    recursion_limit=50  # ìµœëŒ€ 50ë²ˆ ë°˜ë³µ
)

# ì‚¬ì´í´ ê°ì§€
def detect_cycles(graph: StateGraph):
    """ê·¸ë˜í”„ ì •ì˜ ì‹œ ì‚¬ì´í´ ê°ì§€"""
    visited = set()
    rec_stack = set()
    
    def has_cycle(node):
        visited.add(node)
        rec_stack.add(node)
        
        for neighbor in graph.edges.get(node, []):
            if neighbor not in visited:
                if has_cycle(neighbor):
                    return True
            elif neighbor in rec_stack:
                return True
                
        rec_stack.remove(node)
        return False
```

### 3. í†µí•© ì‹œ ê³ ë ¤ì‚¬í•­

#### ë²„ì „ í˜¸í™˜ì„±
```python
# ë²„ì „ ì²´í¬
REQUIRED_VERSIONS = {
    "langgraph": ">=0.1.0",
    "claude-code": ">=1.0.0",
    "langchain": ">=0.2.0"
}

def check_compatibility():
    """ë²„ì „ í˜¸í™˜ì„± ê²€ì‚¬"""
    import pkg_resources
    
    for package, version_spec in REQUIRED_VERSIONS.items():
        try:
            pkg_resources.require(f"{package}{version_spec}")
        except pkg_resources.DistributionNotFound:
            raise ImportError(f"{package} not installed")
        except pkg_resources.VersionConflict as e:
            raise ImportError(f"Version conflict: {e}")
```

#### ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
```python
# ë¦¬ì†ŒìŠ¤ ì •ë¦¬
class ResourceManager:
    def __init__(self):
        self.resources = []
        
    def register(self, resource):
        self.resources.append(resource)
        
    async def cleanup(self):
        """ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        for resource in self.resources:
            if hasattr(resource, 'close'):
                await resource.close()
            elif hasattr(resource, 'cleanup'):
                await resource.cleanup()
                
# Context manager íŒ¨í„´
from contextlib import asynccontextmanager

@asynccontextmanager
async def langgraph_session():
    """LangGraph ì„¸ì…˜ ê´€ë¦¬"""
    graph = None
    try:
        graph = create_graph()
        yield graph
    finally:
        if graph:
            await graph.cleanup()
```

## ê²°ë¡ 

Claude Codeì™€ LangGraphëŠ” ê°ê°:
- **Claude Code**: í„°ë¯¸ë„ ê¸°ë°˜ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ MCPë¥¼ í†µí•œ ë„êµ¬ í†µí•©
- **LangGraph**: ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ì—”ì§„ìœ¼ë¡œ ë³µì¡í•œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

ë‘ ê¸°ìˆ ì„ í†µí•©í•˜ë©´:
1. Claude Codeê°€ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì—­í• 
2. LangGraphê°€ ë°±ì—”ë“œ ì›Œí¬í”Œë¡œìš° ì—”ì§„ ì—­í• 
3. MCPê°€ ë‘˜ ì‚¬ì´ì˜ í†µì‹  í”„ë¡œí† ì½œ ì—­í• 

ì´ë¥¼ í†µí•´ ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ AI ê°œë°œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.